{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyNEh9GwzaOi5G7ZPDd97AZl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ua-datalab/NLP-Speech/blob/main/Intro_to_Semantic_Search/Intro_to_Semantic_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " <center> <h1> Introduction to Semantic Search\n",
        "\n",
        "![](https://raw.githubusercontent.com/ua-datalab/NLP-Speech/main/Intro_to_Semantic_Search/Semantic-Search.png)"
      ],
      "metadata": {
        "id": "esW64GYXpuN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Housekeeping\n",
        "1. Check that the recording is on\n",
        "2. Check audio and screenshare\n",
        "3. Share link to notebook in chat\n",
        "4. Light mode and font size\n",
        "5. Cohere signup and API key gen\n"
      ],
      "metadata": {
        "id": "zSiOw6GP23MB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "Semantic search operates at the level of meaning and context. When provided with an archive of documents, it is built to sorting through a high volume of content, and return an answer for the query by aggregating.\n",
        "\n",
        "The results of the semantic search bring together the aggregated information from several sources, to enrich the response.\n",
        "\n",
        "There are two important things a semantic search needs to return:\n",
        "- Accurate information that is related to the query\n",
        "- Rankings for the information, based on how close it is to the query."
      ],
      "metadata": {
        "id": "gng_CuB_qvPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What are the components needed for semantic search?\n",
        "- A language model with embeddings\n",
        "- A dataset with information in a query-response, or topic-writeup format\n",
        "- An index\n",
        "- A user-provided query, appropriately processed\n",
        "\n"
      ],
      "metadata": {
        "id": "Yp7mpOq3bE7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How does semantic search work?\n",
        "\n",
        " The first thing semantic search needs is a computer-readable formatting of human language, indicating how words are connected to each other to map it meaning. This utilizes a language model that assign syntactic and semantic tags to words, connects them to their lexemes, and finds relations between them to build context. This enables the engine to connect synonyms, hyper- and hyponyms, and see words as more than blocks of letters."
      ],
      "metadata": {
        "id": "7ZMZzeoGbMn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic and keyword searches- different utilities\n",
        "\n",
        "Keyword searches are a great, lightweight tool for finding documents with the words we need. When combined with search tools adn conditionals, they can access and retreive information based on the user input. But, they have some limitations:\n",
        "-  They cannot disambiguate between contexts as the engine does not have information on entities and relations (Apple the company and computers, vs apple the fruit and peanut butter).\n",
        "- They require exact query words\n",
        "- They can be hacked with things like keyword stuffing, because they look for words, not how they are used\n",
        "\n",
        "Semantic search uses all the building blocks for NLP, as well as the building blocks of LLMs, and operates at a meaning level. It is a heavier system, but has higher utility."
      ],
      "metadata": {
        "id": "qyhl7bfWbPt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Definitions\n",
        "\n",
        "\n",
        "- Entity- briefly, nouns in a given text\n",
        "- Query- the user-provided input that will be used to perform the search\n",
        "- Vector representations\n",
        "  - Mathematical representation of data (such as words) in a multi-dimensional space, as an array of numbers.\n",
        "  - Can capture relationships among data points using the numerical representation.\n",
        "  - Work at the word level\n",
        "  - They do not inherently encode semantic meaning.\n",
        "- Embeddings\n",
        "  - A type of vector representation that captures relationships at the lexcical and sentence levels\n",
        "  - Words that share meaning are closer to each other than those that don't\n",
        "  - It is **learned from data**\n",
        "  - Used to capture semantic content, relationships, or patterns between objects.\n",
        "  - They map discrete objects (like words or items) into continuous vector spaces.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/ua-datalab/NLP-Speech/main/Intro_to_Semantic_Search/vector-representation.png\" width=\"350\"/> </center>\n",
        "\n",
        "- Semantic web: a representation of the world wide web that is machine interpretable, where information is interconnected\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/ua-datalab/NLP-Speech/refs/heads/main/Intro_to_Semantic_Search/RDF_example_extended.svg\" width=\"350\"/> </center>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kTrUN25RpwjV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A few steps that lead semantic search in Google\n",
        "\n",
        "- Information is represented in the form of knowledge graphs, as entities and relations. Leads to RankBrain in 2015.\n",
        "- [Google introduces Hummingbird](https://www.searchenginejournal.com/google-algorithm-history/hummingbird-update/)\n",
        "- [BERT- bidirectional encoder representations from transformers](https://blog.google/products/search/search-language-understanding-bert/)"
      ],
      "metadata": {
        "id": "x9Gea80ZqGMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A human approach to semantic search\n",
        "\n",
        "Consider how you would interpret the following query, and break it down into information that you will need in order to provide a result:\n",
        "\n",
        "> What is Dune?"
      ],
      "metadata": {
        "id": "ltxfKkq5qMD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some working examples\n",
        "\n",
        "We will call pre-trained models or embeddings, and implement semantic search in a few ways:\n",
        "1. We provide the documents, utilize embeddings to retreive information\n",
        "2. We query a dataset created with information of a specific nature (factual questions and answers, wikipedia corpus), and assess if our search results provide useable results.\n",
        "\n",
        "An example of a wikipedia dataset with embeddings:  https://huggingface.co/datasets/olmer/wiki_mpnet_embeddings"
      ],
      "metadata": {
        "id": "OOSr8IIyqO1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cohere\n",
        "\n",
        "[An AI platform](https://docs.cohere.com/docs/models) that offers pre-trained SOTA models, an easy set of multi-platform tools to run them in, as well as educational content.\n",
        "\n",
        "One of the simple out-of-the-box options for LLM research.\n",
        "\n",
        "## Sign up and access an API key.\n",
        "\n",
        "1. [Click here to sign up to Cohere](https://os.cohere.ai/).\n",
        "2. Connect to the cohere dashboard, after signing in\n",
        "3. Copy your API key from the API key section\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ua-datalab/NLP-Speech/main/Intro_to_Semantic_Search/cohere_dashboard.png\" width=\"150\"/>"
      ],
      "metadata": {
        "id": "NipTk6hawnas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1: build a simple semantic search engine with Cohere.\n",
        "\n",
        "How do we build features like StackOverflow's \"similar questions\" feature?\n",
        "\n",
        "Basic breakdown of steps:\n",
        "1. Get an archive of questions.\n",
        "2. [Embed](https://docs.cohere.ai/embed-reference/) the archive to power the semantic search.\n",
        "3. Create a search function using an index and nearest neighbor search.\n",
        "4. Return all questions in the question bank which bear a high degree of similarity to the user query.\n",
        "\n",
        "Source for code: https://github.com/cohere-ai/notebooks/blob/main/notebooks/guides/Basic_Semantic_Search.ipynb"
      ],
      "metadata": {
        "id": "Sur1TWOH0vi7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup\n",
        "\n"
      ],
      "metadata": {
        "id": "oOKwJ_Ul0EeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up and imports:\n",
        "!pip install \"cohere<5\" umap-learn altair annoy datasets tqdm"
      ],
      "metadata": {
        "id": "8zxXdlxmpsDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qrs1EFkhmMuU"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import cohere\n",
        "from tqdm import tqdm\n",
        "from datasets import load_dataset\n",
        "import umap\n",
        "import altair as alt\n",
        "from annoy import AnnoyIndex\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's access a language model and open the cohere API."
      ],
      "metadata": {
        "id": "uMOfvo-O10lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"embed-english-v3.0\"\n",
        "api_key = \"\"\n",
        "#api_key = open('cohere_api.txt').read()\n",
        "input_type_embed = \"search_document\"\n",
        "\n",
        "# Now we'll set up the cohere client.\n",
        "co = cohere.Client(api_key)"
      ],
      "metadata": {
        "id": "eJoeMiSkpjOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examining the dataset\n",
        "\n",
        "Next, we load our dataset, which is a set of questions and their answers. Today, we are using the [trec](https://www.tensorflow.org/datasets/catalog/trec) dataset which is made up of questions and their categories. For this, we use the `datasets` library, which can access all datasets on Hugging Face."
      ],
      "metadata": {
        "id": "SYSWyvbG3Z78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset_builder\n",
        "ds_builder = load_dataset_builder(\"trec\")\n"
      ],
      "metadata": {
        "id": "I0SdexHy1_kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect dataset description\n",
        "ds_builder.info.description"
      ],
      "metadata": {
        "id": "2Rle-Ujt4dnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dataset\n",
        "dataset = load_dataset(\"trec\", split=\"train\")\n",
        "\n",
        "# Import into a pandas dataframe, take only the first 3000 rows\n",
        "# We can change this\n",
        "df = pd.DataFrame(dataset)[:3000]\n",
        "\n",
        "# Preview the data to ensure it has loaded correctly\n",
        "df.head(10)\n",
        "\n"
      ],
      "metadata": {
        "id": "cHGmZ_dG4rum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create embeddings for the `trec` question bank:"
      ],
      "metadata": {
        "id": "CYP9G_Dw48vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the embeddings\n",
        "embeds = co.embed(texts=list(df['text']),\n",
        "                  model=model_name,\n",
        "                  input_type=input_type_embed).embeddings"
      ],
      "metadata": {
        "id": "dhHKq7ra44Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the dimensions of the embeddings\n",
        "embeds = np.array(embeds)\n",
        "embeds.shape"
      ],
      "metadata": {
        "id": "g-rGMUvB5Ftk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need an index that can store the embeddings and access them in an optimized way. This example uses [Annoy](https://github.com/spotify/annoy).\n",
        "\n",
        "After building the index with our dataset, we can use it to retrieve the nearest neighbors either of existing questions, or of new questions that we embed."
      ],
      "metadata": {
        "id": "vfJ-hOxE5Gf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the search index, pass the size of embedding\n",
        "search_index = AnnoyIndex(embeds.shape[1], 'angular')\n",
        "# Add all the vectors to the search index\n",
        "for i in range(len(embeds)):\n",
        "    search_index.add_item(i, embeds[i])\n",
        "\n",
        "search_index.build(10) # 10 trees\n",
        "search_index.save('test.ann')"
      ],
      "metadata": {
        "id": "SJu9J0r85YYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Providing a user search.\n",
        "\n",
        "Edit the string in \"query\" variable to add your question.\n",
        "\n",
        "Note: We have only called the first 3000 rows in the dataset. We may need more or less data to get the right answer.**bold text**"
      ],
      "metadata": {
        "id": "a-qHm-Ao54yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is the president of the US?\"\n",
        "input_type_query = \"search_query\"\n",
        "\n",
        "# Get the query's embedding\n",
        "query_embed = co.embed(texts=[query],\n",
        "                  model=model_name,\n",
        "                  input_type=input_type_query).embeddings\n",
        "\n",
        "# Retrieve the nearest neighbors\n",
        "similar_item_ids = search_index.get_nns_by_vector(query_embed[0],10,\n",
        "                                                include_distances=True)\n",
        "# Format the results\n",
        "query_results = pd.DataFrame(data={'texts': df.iloc[similar_item_ids[0]]['text'],\n",
        "                             'distance': similar_item_ids[1]})\n",
        "\n",
        "\n",
        "print(f\"Query:'{query}'\\nNearest neighbors:\")\n",
        "print(query_results) # NOTE: Your results might look slightly different to ours."
      ],
      "metadata": {
        "id": "kngwl51l5syb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Thoughts:\n",
        "When we have a small and limited dataset, our search results will reflect the size of our data, and be limited as well.\n",
        "\n",
        "For semantic search at scale, we will need embeddings from a pre-trained model at scale."
      ],
      "metadata": {
        "id": "nJHbfu9K6hzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2: Searching Wikipedia with Cohere's language model"
      ],
      "metadata": {
        "id": "wJ1zkoPy7fYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and examine the dataset:\n"
      ],
      "metadata": {
        "id": "IpklF2ow8NTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#Load at max 1000 documents + embeddings\n",
        "max_docs = 5000\n",
        "docs_stream = load_dataset(f\"Cohere/wikipedia-22-12-simple-embeddings\", split=\"train\", streaming=True)\n",
        "\n",
        "docs = []\n",
        "doc_embeddings = []\n",
        "\n",
        "for doc in docs_stream:\n",
        "    docs.append(doc)\n",
        "    doc_embeddings.append(doc['emb'])\n",
        "    if len(docs) >= max_docs:\n",
        "        break\n",
        "\n",
        "doc_embeddings = torch.tensor(doc_embeddings)"
      ],
      "metadata": {
        "id": "jHUkJE8L7e9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check shape of output. It should have 1000 embeddings vectors, with 768 values each\n",
        "doc_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkTN3NYr6PCH",
        "outputId": "c44faf34-a063-4f9f-de07-b76afb3e69f5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5000, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the query, then embed it\n",
        "query = 'When did Albert Einstein die?'\n",
        "response = co.embed(texts=[query], model='multilingual-22-12')\n",
        "query_embedding = response.embeddings\n",
        "query_embedding = torch.tensor(query_embedding)\n",
        "\n",
        "# Compute dot score between query embedding and document embeddings\n",
        "dot_scores = torch.mm(query_embedding, doc_embeddings.transpose(0, 1))\n",
        "top_k = torch.topk(dot_scores, k=3)\n",
        "\n",
        "# Print results\n",
        "print(\"Query:\", query)\n",
        "for doc_id in top_k.indices[0].tolist():\n",
        "    print(docs[doc_id]['title'])\n",
        "    print(docs[doc_id]['text'], \"\\n\")"
      ],
      "metadata": {
        "id": "gNb-6K316hl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Thoughts\n",
        "In this example, we are able to get information that is a lot more than we asked for. Our limitations continue to be data size (1000-5000 documents), and ranking (when information is extracted from one document, it may not be in the same format as the question asked."
      ],
      "metadata": {
        "id": "NnkEyb0l-48I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distilbert\n",
        "\n",
        "Next, we will try another available option- accessing a model pre-trained on entries from the website Quora.\n",
        "\n",
        "This is a much bigger model, with more data. With this code, you can play with more models and options.\n",
        "\n",
        "Source for code: https://github.com/UKPLab/sentence-transformers/tree/master/examples/applications/semantic-search\n",
        "\n"
      ],
      "metadata": {
        "id": "a5PFWi-d_bWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "sDFDKDkkCHHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "import time\n",
        "import gzip\n",
        "import os\n",
        "import torch\n",
        "import csv\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "  print(\"Warning: No GPU found. Please add GPU to your notebook\")"
      ],
      "metadata": {
        "id": "WPeto4fh9hEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and limit size to 100k:\n",
        "model_name = 'quora-distilbert-multilingual'\n",
        "model = SentenceTransformer(model_name)\n",
        "\n",
        "url = \"http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\"\n",
        "dataset_path = \"quora_duplicate_questions.tsv\"\n",
        "max_corpus_size = 100000\n",
        "\n",
        "# Check if the dataset exists. If not, download and extract\n",
        "# Download dataset if needed\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(\"Download dataset\")\n",
        "    util.http_get(url, dataset_path)\n",
        "\n",
        "# Get all unique sentences from the file\n",
        "corpus_sentences = set()\n",
        "with open(dataset_path, encoding='utf8') as fIn:\n",
        "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_MINIMAL)\n",
        "    for row in reader:\n",
        "        corpus_sentences.add(row['question1'])\n",
        "        if len(corpus_sentences) >= max_corpus_size:\n",
        "            break\n",
        "\n",
        "        corpus_sentences.add(row['question2'])\n",
        "        if len(corpus_sentences) >= max_corpus_size:\n",
        "            break\n",
        "\n",
        "corpus_sentences = list(corpus_sentences)"
      ],
      "metadata": {
        "id": "YjEINy6lFSOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Encode the corpus. This might take a while\")\n",
        "corpus_embeddings = model.encode(corpus_sentences, show_progress_bar=True, convert_to_tensor=True)\n",
        "\n",
        "###############################\n",
        "print(\"Corpus loaded with {} sentences / embeddings\".format(len(corpus_sentences)))"
      ],
      "metadata": {
        "id": "baGILlRtFWZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up a function to encode the user query:"
      ],
      "metadata": {
        "id": "1-_AK_rCCVby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that searches the corpus and prints questions that match our search\n",
        "def search(inp_question):\n",
        "    start_time = time.time()\n",
        "    question_embedding = model.encode(inp_question, convert_to_tensor=True)\n",
        "    hits = util.semantic_search(question_embedding, corpus_embeddings)\n",
        "    end_time = time.time()\n",
        "    hits = hits[0]  #Get the hits for the first query\n",
        "\n",
        "    print(\"Input question:\", inp_question)\n",
        "    print(\"Results (after {:.3f} seconds):\".format(end_time-start_time))\n",
        "    for hit in hits[0:5]:\n",
        "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], corpus_sentences[hit['corpus_id']]))"
      ],
      "metadata": {
        "id": "Kb3bAYLxFffE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample queries and Similarity"
      ],
      "metadata": {
        "id": "mrfVJw1VCvtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search(\"How can I learn Java online?\")"
      ],
      "metadata": {
        "id": "0BBt86hYCE9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search(\"What is the capital of the France?\")"
      ],
      "metadata": {
        "id": "xgGYBMfEDKqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some more at-scale demos\n",
        "\n",
        "- [Semantic experiences- a set of examples for integrating semantic information in NLP](https://research.google.com/semanticexperiences/)\n",
        "- [Semantris- ML powered word association tetris](https://research.google.com/semantris/)\n"
      ],
      "metadata": {
        "id": "Jcizwy370m-l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "1. [GloVe: Global Vectors for Word Representation](https://aclanthology.org/D14-1162/)\n",
        "2. [Wide range screening of algorithmic bias in word embedding models using large sentiment lexicons reveals underreported bias types](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0231189#pone.0231189.ref009)\n",
        "3. [LLM Vector Embedding](https://llmbuilt.com/llm-vector-embedding/)\n",
        "4. [Integrating Vector Databases with LLMs: A Hands-On Guide](https://mlengineering.medium.com/integrating-vector-databases-with-llms-a-hands-on-guide-82d2463114fb)\n",
        "5. [What are vector embeddings?](https://www.elastic.co/what-is/vector-embedding)"
      ],
      "metadata": {
        "id": "cOo6qhVBG43Z"
      }
    }
  ]
}